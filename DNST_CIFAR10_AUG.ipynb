{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DNST_CIFAR10_AUG.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/papasanimohansrinivas/papasanimohansrinivas.github.io/blob/master/DNST_CIFAR10_AUG.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "K70hAckqg0EA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b4958d80-f976-4f95-e08d-40e996af04c8"
      },
      "cell_type": "code",
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "wVIx_KIigxPV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.layers import Concatenate\n",
        "from keras.optimizers import Adam,RMSprop"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UNHw6luQg3gc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
        "# backend\n",
        "import tensorflow as tf\n",
        "from keras import backend as k\n",
        "\n",
        "# Don't pre-allocate memory; allocate as-needed\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "# Create a session with the above options specified.\n",
        "k.tensorflow_backend.set_session(tf.Session(config=config))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dsO_yGxcg5D8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 16\n",
        "l = 18\n",
        "num_filter = 16\n",
        "compression = 0.3\n",
        "dropout_rate = 0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mB7o3zu1g6eT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load CIFAR10 Data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "img_height, img_width, channel = x_train.shape[1],x_train.shape[2],x_train.shape[3]\n",
        "\n",
        "# convert to one hot encoing \n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ee-sge5Kg7vr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Dense Block\n",
        "def add_denseblock(input, num_filter = 12, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    temp = input\n",
        "    global l\n",
        "    for _ in range(l):\n",
        "        BatchNorm = BatchNormalization()(temp)\n",
        "        relu = Activation('relu')(BatchNorm)\n",
        "        Conv2D_3_3 = Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu)\n",
        "        if dropout_rate>0:\n",
        "          Conv2D_3_3 = Dropout(dropout_rate)(Conv2D_3_3)\n",
        "        concat = Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
        "        \n",
        "        temp = concat\n",
        "        \n",
        "    return temp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OOP6IPsGhBwb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def add_transition(input, num_filter = 12, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    Conv2D_BottleNeck = Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
        "    if dropout_rate>0:\n",
        "      Conv2D_BottleNeck = Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
        "    avg = AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
        "    \n",
        "    return avg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0RaKFpubhDIC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def output_layer(input):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    AvgPooling = AveragePooling2D(pool_size=(2,2))(relu)\n",
        "    flat = Flatten()(AvgPooling)\n",
        "    output = Dense(num_classes, activation='softmax')(flat)\n",
        "    \n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "anPCpQWhhGb7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_filter = 16\n",
        "dropout_rate = 0.0\n",
        "l = 18\n",
        "input = Input(shape=(img_height, img_width, channel,))\n",
        "First_Conv2D = Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(input)\n",
        "\n",
        "First_Block = add_denseblock(First_Conv2D, num_filter, dropout_rate)\n",
        "First_Transition = add_transition(First_Block, num_filter, dropout_rate)\n",
        "\n",
        "Second_Block = add_denseblock(First_Transition, num_filter, dropout_rate)\n",
        "Second_Transition = add_transition(Second_Block, num_filter, dropout_rate)\n",
        "\n",
        "Third_Block = add_denseblock(Second_Transition, num_filter, dropout_rate)\n",
        "Third_Transition = add_transition(Third_Block, num_filter, dropout_rate)\n",
        "\n",
        "Last_Block = add_denseblock(Third_Transition,  num_filter, dropout_rate)\n",
        "output = output_layer(Last_Block)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1kFh7pdxhNtT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 12029
        },
        "outputId": "c772c0f9-04da-4a2d-d095-5fb99433859a"
      },
      "cell_type": "code",
      "source": [
        "model = Model(inputs=[input], outputs=[output])\n",
        "model.summary()"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_18 (InputLayer)           (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_552 (Conv2D)             (None, 32, 32, 16)   432         input_18[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_552 (BatchN (None, 32, 32, 16)   64          conv2d_552[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_550 (Activation)     (None, 32, 32, 16)   0           batch_normalization_552[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_553 (Conv2D)             (None, 32, 32, 4)    576         activation_550[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_485 (Concatenate)   (None, 32, 32, 20)   0           conv2d_552[0][0]                 \n",
            "                                                                 conv2d_553[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_553 (BatchN (None, 32, 32, 20)   80          concatenate_485[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_551 (Activation)     (None, 32, 32, 20)   0           batch_normalization_553[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_554 (Conv2D)             (None, 32, 32, 4)    720         activation_551[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_486 (Concatenate)   (None, 32, 32, 24)   0           concatenate_485[0][0]            \n",
            "                                                                 conv2d_554[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_554 (BatchN (None, 32, 32, 24)   96          concatenate_486[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_552 (Activation)     (None, 32, 32, 24)   0           batch_normalization_554[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_555 (Conv2D)             (None, 32, 32, 4)    864         activation_552[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_487 (Concatenate)   (None, 32, 32, 28)   0           concatenate_486[0][0]            \n",
            "                                                                 conv2d_555[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_555 (BatchN (None, 32, 32, 28)   112         concatenate_487[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_553 (Activation)     (None, 32, 32, 28)   0           batch_normalization_555[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_556 (Conv2D)             (None, 32, 32, 4)    1008        activation_553[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_488 (Concatenate)   (None, 32, 32, 32)   0           concatenate_487[0][0]            \n",
            "                                                                 conv2d_556[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_556 (BatchN (None, 32, 32, 32)   128         concatenate_488[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_554 (Activation)     (None, 32, 32, 32)   0           batch_normalization_556[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_557 (Conv2D)             (None, 32, 32, 4)    1152        activation_554[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_489 (Concatenate)   (None, 32, 32, 36)   0           concatenate_488[0][0]            \n",
            "                                                                 conv2d_557[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_557 (BatchN (None, 32, 32, 36)   144         concatenate_489[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_555 (Activation)     (None, 32, 32, 36)   0           batch_normalization_557[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_558 (Conv2D)             (None, 32, 32, 4)    1296        activation_555[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_490 (Concatenate)   (None, 32, 32, 40)   0           concatenate_489[0][0]            \n",
            "                                                                 conv2d_558[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_558 (BatchN (None, 32, 32, 40)   160         concatenate_490[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_556 (Activation)     (None, 32, 32, 40)   0           batch_normalization_558[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_559 (Conv2D)             (None, 32, 32, 4)    1440        activation_556[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_491 (Concatenate)   (None, 32, 32, 44)   0           concatenate_490[0][0]            \n",
            "                                                                 conv2d_559[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_559 (BatchN (None, 32, 32, 44)   176         concatenate_491[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_557 (Activation)     (None, 32, 32, 44)   0           batch_normalization_559[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_560 (Conv2D)             (None, 32, 32, 4)    1584        activation_557[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_492 (Concatenate)   (None, 32, 32, 48)   0           concatenate_491[0][0]            \n",
            "                                                                 conv2d_560[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_560 (BatchN (None, 32, 32, 48)   192         concatenate_492[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_558 (Activation)     (None, 32, 32, 48)   0           batch_normalization_560[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_561 (Conv2D)             (None, 32, 32, 4)    1728        activation_558[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_493 (Concatenate)   (None, 32, 32, 52)   0           concatenate_492[0][0]            \n",
            "                                                                 conv2d_561[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_561 (BatchN (None, 32, 32, 52)   208         concatenate_493[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_559 (Activation)     (None, 32, 32, 52)   0           batch_normalization_561[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_562 (Conv2D)             (None, 32, 32, 4)    1872        activation_559[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_494 (Concatenate)   (None, 32, 32, 56)   0           concatenate_493[0][0]            \n",
            "                                                                 conv2d_562[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_562 (BatchN (None, 32, 32, 56)   224         concatenate_494[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_560 (Activation)     (None, 32, 32, 56)   0           batch_normalization_562[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_563 (Conv2D)             (None, 32, 32, 4)    2016        activation_560[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_495 (Concatenate)   (None, 32, 32, 60)   0           concatenate_494[0][0]            \n",
            "                                                                 conv2d_563[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_563 (BatchN (None, 32, 32, 60)   240         concatenate_495[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_561 (Activation)     (None, 32, 32, 60)   0           batch_normalization_563[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_564 (Conv2D)             (None, 32, 32, 4)    2160        activation_561[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_496 (Concatenate)   (None, 32, 32, 64)   0           concatenate_495[0][0]            \n",
            "                                                                 conv2d_564[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_564 (BatchN (None, 32, 32, 64)   256         concatenate_496[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_562 (Activation)     (None, 32, 32, 64)   0           batch_normalization_564[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_565 (Conv2D)             (None, 32, 32, 4)    2304        activation_562[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_497 (Concatenate)   (None, 32, 32, 68)   0           concatenate_496[0][0]            \n",
            "                                                                 conv2d_565[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_565 (BatchN (None, 32, 32, 68)   272         concatenate_497[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_563 (Activation)     (None, 32, 32, 68)   0           batch_normalization_565[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_566 (Conv2D)             (None, 32, 32, 4)    2448        activation_563[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_498 (Concatenate)   (None, 32, 32, 72)   0           concatenate_497[0][0]            \n",
            "                                                                 conv2d_566[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_566 (BatchN (None, 32, 32, 72)   288         concatenate_498[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_564 (Activation)     (None, 32, 32, 72)   0           batch_normalization_566[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_567 (Conv2D)             (None, 32, 32, 4)    2592        activation_564[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_499 (Concatenate)   (None, 32, 32, 76)   0           concatenate_498[0][0]            \n",
            "                                                                 conv2d_567[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_567 (BatchN (None, 32, 32, 76)   304         concatenate_499[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_565 (Activation)     (None, 32, 32, 76)   0           batch_normalization_567[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_568 (Conv2D)             (None, 32, 32, 4)    2736        activation_565[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_500 (Concatenate)   (None, 32, 32, 80)   0           concatenate_499[0][0]            \n",
            "                                                                 conv2d_568[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_568 (BatchN (None, 32, 32, 80)   320         concatenate_500[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_566 (Activation)     (None, 32, 32, 80)   0           batch_normalization_568[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_569 (Conv2D)             (None, 32, 32, 4)    2880        activation_566[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_501 (Concatenate)   (None, 32, 32, 84)   0           concatenate_500[0][0]            \n",
            "                                                                 conv2d_569[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_569 (BatchN (None, 32, 32, 84)   336         concatenate_501[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_567 (Activation)     (None, 32, 32, 84)   0           batch_normalization_569[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_570 (Conv2D)             (None, 32, 32, 4)    3024        activation_567[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_502 (Concatenate)   (None, 32, 32, 88)   0           concatenate_501[0][0]            \n",
            "                                                                 conv2d_570[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_570 (BatchN (None, 32, 32, 88)   352         concatenate_502[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_568 (Activation)     (None, 32, 32, 88)   0           batch_normalization_570[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_571 (Conv2D)             (None, 32, 32, 4)    352         activation_568[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_66 (AveragePo (None, 16, 16, 4)    0           conv2d_571[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_571 (BatchN (None, 16, 16, 4)    16          average_pooling2d_66[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_569 (Activation)     (None, 16, 16, 4)    0           batch_normalization_571[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_572 (Conv2D)             (None, 16, 16, 4)    144         activation_569[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_503 (Concatenate)   (None, 16, 16, 8)    0           average_pooling2d_66[0][0]       \n",
            "                                                                 conv2d_572[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_572 (BatchN (None, 16, 16, 8)    32          concatenate_503[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_570 (Activation)     (None, 16, 16, 8)    0           batch_normalization_572[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_573 (Conv2D)             (None, 16, 16, 4)    288         activation_570[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_504 (Concatenate)   (None, 16, 16, 12)   0           concatenate_503[0][0]            \n",
            "                                                                 conv2d_573[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_573 (BatchN (None, 16, 16, 12)   48          concatenate_504[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_571 (Activation)     (None, 16, 16, 12)   0           batch_normalization_573[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_574 (Conv2D)             (None, 16, 16, 4)    432         activation_571[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_505 (Concatenate)   (None, 16, 16, 16)   0           concatenate_504[0][0]            \n",
            "                                                                 conv2d_574[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_574 (BatchN (None, 16, 16, 16)   64          concatenate_505[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_572 (Activation)     (None, 16, 16, 16)   0           batch_normalization_574[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_575 (Conv2D)             (None, 16, 16, 4)    576         activation_572[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_506 (Concatenate)   (None, 16, 16, 20)   0           concatenate_505[0][0]            \n",
            "                                                                 conv2d_575[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_575 (BatchN (None, 16, 16, 20)   80          concatenate_506[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_573 (Activation)     (None, 16, 16, 20)   0           batch_normalization_575[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_576 (Conv2D)             (None, 16, 16, 4)    720         activation_573[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_507 (Concatenate)   (None, 16, 16, 24)   0           concatenate_506[0][0]            \n",
            "                                                                 conv2d_576[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_576 (BatchN (None, 16, 16, 24)   96          concatenate_507[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_574 (Activation)     (None, 16, 16, 24)   0           batch_normalization_576[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_577 (Conv2D)             (None, 16, 16, 4)    864         activation_574[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_508 (Concatenate)   (None, 16, 16, 28)   0           concatenate_507[0][0]            \n",
            "                                                                 conv2d_577[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_577 (BatchN (None, 16, 16, 28)   112         concatenate_508[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_575 (Activation)     (None, 16, 16, 28)   0           batch_normalization_577[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_578 (Conv2D)             (None, 16, 16, 4)    1008        activation_575[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_509 (Concatenate)   (None, 16, 16, 32)   0           concatenate_508[0][0]            \n",
            "                                                                 conv2d_578[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_578 (BatchN (None, 16, 16, 32)   128         concatenate_509[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_576 (Activation)     (None, 16, 16, 32)   0           batch_normalization_578[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_579 (Conv2D)             (None, 16, 16, 4)    1152        activation_576[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_510 (Concatenate)   (None, 16, 16, 36)   0           concatenate_509[0][0]            \n",
            "                                                                 conv2d_579[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_579 (BatchN (None, 16, 16, 36)   144         concatenate_510[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_577 (Activation)     (None, 16, 16, 36)   0           batch_normalization_579[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_580 (Conv2D)             (None, 16, 16, 4)    1296        activation_577[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_511 (Concatenate)   (None, 16, 16, 40)   0           concatenate_510[0][0]            \n",
            "                                                                 conv2d_580[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_580 (BatchN (None, 16, 16, 40)   160         concatenate_511[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_578 (Activation)     (None, 16, 16, 40)   0           batch_normalization_580[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_581 (Conv2D)             (None, 16, 16, 4)    1440        activation_578[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_512 (Concatenate)   (None, 16, 16, 44)   0           concatenate_511[0][0]            \n",
            "                                                                 conv2d_581[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_581 (BatchN (None, 16, 16, 44)   176         concatenate_512[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_579 (Activation)     (None, 16, 16, 44)   0           batch_normalization_581[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_582 (Conv2D)             (None, 16, 16, 4)    1584        activation_579[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_513 (Concatenate)   (None, 16, 16, 48)   0           concatenate_512[0][0]            \n",
            "                                                                 conv2d_582[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_582 (BatchN (None, 16, 16, 48)   192         concatenate_513[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_580 (Activation)     (None, 16, 16, 48)   0           batch_normalization_582[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_583 (Conv2D)             (None, 16, 16, 4)    1728        activation_580[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_514 (Concatenate)   (None, 16, 16, 52)   0           concatenate_513[0][0]            \n",
            "                                                                 conv2d_583[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_583 (BatchN (None, 16, 16, 52)   208         concatenate_514[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_581 (Activation)     (None, 16, 16, 52)   0           batch_normalization_583[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_584 (Conv2D)             (None, 16, 16, 4)    1872        activation_581[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_515 (Concatenate)   (None, 16, 16, 56)   0           concatenate_514[0][0]            \n",
            "                                                                 conv2d_584[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_584 (BatchN (None, 16, 16, 56)   224         concatenate_515[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_582 (Activation)     (None, 16, 16, 56)   0           batch_normalization_584[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_585 (Conv2D)             (None, 16, 16, 4)    2016        activation_582[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_516 (Concatenate)   (None, 16, 16, 60)   0           concatenate_515[0][0]            \n",
            "                                                                 conv2d_585[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_585 (BatchN (None, 16, 16, 60)   240         concatenate_516[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_583 (Activation)     (None, 16, 16, 60)   0           batch_normalization_585[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_586 (Conv2D)             (None, 16, 16, 4)    2160        activation_583[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_517 (Concatenate)   (None, 16, 16, 64)   0           concatenate_516[0][0]            \n",
            "                                                                 conv2d_586[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_586 (BatchN (None, 16, 16, 64)   256         concatenate_517[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_584 (Activation)     (None, 16, 16, 64)   0           batch_normalization_586[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_587 (Conv2D)             (None, 16, 16, 4)    2304        activation_584[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_518 (Concatenate)   (None, 16, 16, 68)   0           concatenate_517[0][0]            \n",
            "                                                                 conv2d_587[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_587 (BatchN (None, 16, 16, 68)   272         concatenate_518[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_585 (Activation)     (None, 16, 16, 68)   0           batch_normalization_587[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_588 (Conv2D)             (None, 16, 16, 4)    2448        activation_585[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_519 (Concatenate)   (None, 16, 16, 72)   0           concatenate_518[0][0]            \n",
            "                                                                 conv2d_588[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_588 (BatchN (None, 16, 16, 72)   288         concatenate_519[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_586 (Activation)     (None, 16, 16, 72)   0           batch_normalization_588[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_589 (Conv2D)             (None, 16, 16, 4)    2592        activation_586[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_520 (Concatenate)   (None, 16, 16, 76)   0           concatenate_519[0][0]            \n",
            "                                                                 conv2d_589[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_589 (BatchN (None, 16, 16, 76)   304         concatenate_520[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_587 (Activation)     (None, 16, 16, 76)   0           batch_normalization_589[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_590 (Conv2D)             (None, 16, 16, 4)    304         activation_587[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_67 (AveragePo (None, 8, 8, 4)      0           conv2d_590[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_590 (BatchN (None, 8, 8, 4)      16          average_pooling2d_67[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_588 (Activation)     (None, 8, 8, 4)      0           batch_normalization_590[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_591 (Conv2D)             (None, 8, 8, 4)      144         activation_588[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_521 (Concatenate)   (None, 8, 8, 8)      0           average_pooling2d_67[0][0]       \n",
            "                                                                 conv2d_591[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_591 (BatchN (None, 8, 8, 8)      32          concatenate_521[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_589 (Activation)     (None, 8, 8, 8)      0           batch_normalization_591[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_592 (Conv2D)             (None, 8, 8, 4)      288         activation_589[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_522 (Concatenate)   (None, 8, 8, 12)     0           concatenate_521[0][0]            \n",
            "                                                                 conv2d_592[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_592 (BatchN (None, 8, 8, 12)     48          concatenate_522[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_590 (Activation)     (None, 8, 8, 12)     0           batch_normalization_592[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_593 (Conv2D)             (None, 8, 8, 4)      432         activation_590[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_523 (Concatenate)   (None, 8, 8, 16)     0           concatenate_522[0][0]            \n",
            "                                                                 conv2d_593[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_593 (BatchN (None, 8, 8, 16)     64          concatenate_523[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_591 (Activation)     (None, 8, 8, 16)     0           batch_normalization_593[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_594 (Conv2D)             (None, 8, 8, 4)      576         activation_591[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_524 (Concatenate)   (None, 8, 8, 20)     0           concatenate_523[0][0]            \n",
            "                                                                 conv2d_594[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_594 (BatchN (None, 8, 8, 20)     80          concatenate_524[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_592 (Activation)     (None, 8, 8, 20)     0           batch_normalization_594[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_595 (Conv2D)             (None, 8, 8, 4)      720         activation_592[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_525 (Concatenate)   (None, 8, 8, 24)     0           concatenate_524[0][0]            \n",
            "                                                                 conv2d_595[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_595 (BatchN (None, 8, 8, 24)     96          concatenate_525[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_593 (Activation)     (None, 8, 8, 24)     0           batch_normalization_595[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_596 (Conv2D)             (None, 8, 8, 4)      864         activation_593[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_526 (Concatenate)   (None, 8, 8, 28)     0           concatenate_525[0][0]            \n",
            "                                                                 conv2d_596[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_596 (BatchN (None, 8, 8, 28)     112         concatenate_526[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_594 (Activation)     (None, 8, 8, 28)     0           batch_normalization_596[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_597 (Conv2D)             (None, 8, 8, 4)      1008        activation_594[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_527 (Concatenate)   (None, 8, 8, 32)     0           concatenate_526[0][0]            \n",
            "                                                                 conv2d_597[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_597 (BatchN (None, 8, 8, 32)     128         concatenate_527[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_595 (Activation)     (None, 8, 8, 32)     0           batch_normalization_597[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_598 (Conv2D)             (None, 8, 8, 4)      1152        activation_595[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_528 (Concatenate)   (None, 8, 8, 36)     0           concatenate_527[0][0]            \n",
            "                                                                 conv2d_598[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_598 (BatchN (None, 8, 8, 36)     144         concatenate_528[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_596 (Activation)     (None, 8, 8, 36)     0           batch_normalization_598[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_599 (Conv2D)             (None, 8, 8, 4)      1296        activation_596[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_529 (Concatenate)   (None, 8, 8, 40)     0           concatenate_528[0][0]            \n",
            "                                                                 conv2d_599[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_599 (BatchN (None, 8, 8, 40)     160         concatenate_529[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_597 (Activation)     (None, 8, 8, 40)     0           batch_normalization_599[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_600 (Conv2D)             (None, 8, 8, 4)      1440        activation_597[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_530 (Concatenate)   (None, 8, 8, 44)     0           concatenate_529[0][0]            \n",
            "                                                                 conv2d_600[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_600 (BatchN (None, 8, 8, 44)     176         concatenate_530[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_598 (Activation)     (None, 8, 8, 44)     0           batch_normalization_600[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_601 (Conv2D)             (None, 8, 8, 4)      1584        activation_598[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_531 (Concatenate)   (None, 8, 8, 48)     0           concatenate_530[0][0]            \n",
            "                                                                 conv2d_601[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_601 (BatchN (None, 8, 8, 48)     192         concatenate_531[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_599 (Activation)     (None, 8, 8, 48)     0           batch_normalization_601[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_602 (Conv2D)             (None, 8, 8, 4)      1728        activation_599[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_532 (Concatenate)   (None, 8, 8, 52)     0           concatenate_531[0][0]            \n",
            "                                                                 conv2d_602[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_602 (BatchN (None, 8, 8, 52)     208         concatenate_532[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_600 (Activation)     (None, 8, 8, 52)     0           batch_normalization_602[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_603 (Conv2D)             (None, 8, 8, 4)      1872        activation_600[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_533 (Concatenate)   (None, 8, 8, 56)     0           concatenate_532[0][0]            \n",
            "                                                                 conv2d_603[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_603 (BatchN (None, 8, 8, 56)     224         concatenate_533[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_601 (Activation)     (None, 8, 8, 56)     0           batch_normalization_603[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_604 (Conv2D)             (None, 8, 8, 4)      2016        activation_601[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_534 (Concatenate)   (None, 8, 8, 60)     0           concatenate_533[0][0]            \n",
            "                                                                 conv2d_604[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_604 (BatchN (None, 8, 8, 60)     240         concatenate_534[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_602 (Activation)     (None, 8, 8, 60)     0           batch_normalization_604[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_605 (Conv2D)             (None, 8, 8, 4)      2160        activation_602[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_535 (Concatenate)   (None, 8, 8, 64)     0           concatenate_534[0][0]            \n",
            "                                                                 conv2d_605[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_605 (BatchN (None, 8, 8, 64)     256         concatenate_535[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_603 (Activation)     (None, 8, 8, 64)     0           batch_normalization_605[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_606 (Conv2D)             (None, 8, 8, 4)      2304        activation_603[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_536 (Concatenate)   (None, 8, 8, 68)     0           concatenate_535[0][0]            \n",
            "                                                                 conv2d_606[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_606 (BatchN (None, 8, 8, 68)     272         concatenate_536[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_604 (Activation)     (None, 8, 8, 68)     0           batch_normalization_606[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_607 (Conv2D)             (None, 8, 8, 4)      2448        activation_604[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_537 (Concatenate)   (None, 8, 8, 72)     0           concatenate_536[0][0]            \n",
            "                                                                 conv2d_607[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_607 (BatchN (None, 8, 8, 72)     288         concatenate_537[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_605 (Activation)     (None, 8, 8, 72)     0           batch_normalization_607[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_608 (Conv2D)             (None, 8, 8, 4)      2592        activation_605[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_538 (Concatenate)   (None, 8, 8, 76)     0           concatenate_537[0][0]            \n",
            "                                                                 conv2d_608[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_608 (BatchN (None, 8, 8, 76)     304         concatenate_538[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_606 (Activation)     (None, 8, 8, 76)     0           batch_normalization_608[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_609 (Conv2D)             (None, 8, 8, 4)      304         activation_606[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_68 (AveragePo (None, 4, 4, 4)      0           conv2d_609[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_609 (BatchN (None, 4, 4, 4)      16          average_pooling2d_68[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_607 (Activation)     (None, 4, 4, 4)      0           batch_normalization_609[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_610 (Conv2D)             (None, 4, 4, 4)      144         activation_607[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_539 (Concatenate)   (None, 4, 4, 8)      0           average_pooling2d_68[0][0]       \n",
            "                                                                 conv2d_610[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_610 (BatchN (None, 4, 4, 8)      32          concatenate_539[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_608 (Activation)     (None, 4, 4, 8)      0           batch_normalization_610[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_611 (Conv2D)             (None, 4, 4, 4)      288         activation_608[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_540 (Concatenate)   (None, 4, 4, 12)     0           concatenate_539[0][0]            \n",
            "                                                                 conv2d_611[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_611 (BatchN (None, 4, 4, 12)     48          concatenate_540[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_609 (Activation)     (None, 4, 4, 12)     0           batch_normalization_611[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_612 (Conv2D)             (None, 4, 4, 4)      432         activation_609[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_541 (Concatenate)   (None, 4, 4, 16)     0           concatenate_540[0][0]            \n",
            "                                                                 conv2d_612[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_612 (BatchN (None, 4, 4, 16)     64          concatenate_541[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_610 (Activation)     (None, 4, 4, 16)     0           batch_normalization_612[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_613 (Conv2D)             (None, 4, 4, 4)      576         activation_610[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_542 (Concatenate)   (None, 4, 4, 20)     0           concatenate_541[0][0]            \n",
            "                                                                 conv2d_613[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_613 (BatchN (None, 4, 4, 20)     80          concatenate_542[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_611 (Activation)     (None, 4, 4, 20)     0           batch_normalization_613[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_614 (Conv2D)             (None, 4, 4, 4)      720         activation_611[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_543 (Concatenate)   (None, 4, 4, 24)     0           concatenate_542[0][0]            \n",
            "                                                                 conv2d_614[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_614 (BatchN (None, 4, 4, 24)     96          concatenate_543[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_612 (Activation)     (None, 4, 4, 24)     0           batch_normalization_614[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_615 (Conv2D)             (None, 4, 4, 4)      864         activation_612[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_544 (Concatenate)   (None, 4, 4, 28)     0           concatenate_543[0][0]            \n",
            "                                                                 conv2d_615[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_615 (BatchN (None, 4, 4, 28)     112         concatenate_544[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_613 (Activation)     (None, 4, 4, 28)     0           batch_normalization_615[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_616 (Conv2D)             (None, 4, 4, 4)      1008        activation_613[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_545 (Concatenate)   (None, 4, 4, 32)     0           concatenate_544[0][0]            \n",
            "                                                                 conv2d_616[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_616 (BatchN (None, 4, 4, 32)     128         concatenate_545[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_614 (Activation)     (None, 4, 4, 32)     0           batch_normalization_616[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_617 (Conv2D)             (None, 4, 4, 4)      1152        activation_614[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_546 (Concatenate)   (None, 4, 4, 36)     0           concatenate_545[0][0]            \n",
            "                                                                 conv2d_617[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_617 (BatchN (None, 4, 4, 36)     144         concatenate_546[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_615 (Activation)     (None, 4, 4, 36)     0           batch_normalization_617[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_618 (Conv2D)             (None, 4, 4, 4)      1296        activation_615[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_547 (Concatenate)   (None, 4, 4, 40)     0           concatenate_546[0][0]            \n",
            "                                                                 conv2d_618[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_618 (BatchN (None, 4, 4, 40)     160         concatenate_547[0][0]            \n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "activation_616 (Activation)     (None, 4, 4, 40)     0           batch_normalization_618[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_619 (Conv2D)             (None, 4, 4, 4)      1440        activation_616[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_548 (Concatenate)   (None, 4, 4, 44)     0           concatenate_547[0][0]            \n",
            "                                                                 conv2d_619[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_619 (BatchN (None, 4, 4, 44)     176         concatenate_548[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_617 (Activation)     (None, 4, 4, 44)     0           batch_normalization_619[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_620 (Conv2D)             (None, 4, 4, 4)      1584        activation_617[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_549 (Concatenate)   (None, 4, 4, 48)     0           concatenate_548[0][0]            \n",
            "                                                                 conv2d_620[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_620 (BatchN (None, 4, 4, 48)     192         concatenate_549[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_618 (Activation)     (None, 4, 4, 48)     0           batch_normalization_620[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_621 (Conv2D)             (None, 4, 4, 4)      1728        activation_618[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_550 (Concatenate)   (None, 4, 4, 52)     0           concatenate_549[0][0]            \n",
            "                                                                 conv2d_621[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_621 (BatchN (None, 4, 4, 52)     208         concatenate_550[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_619 (Activation)     (None, 4, 4, 52)     0           batch_normalization_621[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_622 (Conv2D)             (None, 4, 4, 4)      1872        activation_619[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_551 (Concatenate)   (None, 4, 4, 56)     0           concatenate_550[0][0]            \n",
            "                                                                 conv2d_622[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_622 (BatchN (None, 4, 4, 56)     224         concatenate_551[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_620 (Activation)     (None, 4, 4, 56)     0           batch_normalization_622[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_623 (Conv2D)             (None, 4, 4, 4)      2016        activation_620[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_552 (Concatenate)   (None, 4, 4, 60)     0           concatenate_551[0][0]            \n",
            "                                                                 conv2d_623[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_623 (BatchN (None, 4, 4, 60)     240         concatenate_552[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_621 (Activation)     (None, 4, 4, 60)     0           batch_normalization_623[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_624 (Conv2D)             (None, 4, 4, 4)      2160        activation_621[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_553 (Concatenate)   (None, 4, 4, 64)     0           concatenate_552[0][0]            \n",
            "                                                                 conv2d_624[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_624 (BatchN (None, 4, 4, 64)     256         concatenate_553[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_622 (Activation)     (None, 4, 4, 64)     0           batch_normalization_624[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_625 (Conv2D)             (None, 4, 4, 4)      2304        activation_622[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_554 (Concatenate)   (None, 4, 4, 68)     0           concatenate_553[0][0]            \n",
            "                                                                 conv2d_625[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_625 (BatchN (None, 4, 4, 68)     272         concatenate_554[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_623 (Activation)     (None, 4, 4, 68)     0           batch_normalization_625[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_626 (Conv2D)             (None, 4, 4, 4)      2448        activation_623[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_555 (Concatenate)   (None, 4, 4, 72)     0           concatenate_554[0][0]            \n",
            "                                                                 conv2d_626[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_626 (BatchN (None, 4, 4, 72)     288         concatenate_555[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_624 (Activation)     (None, 4, 4, 72)     0           batch_normalization_626[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_627 (Conv2D)             (None, 4, 4, 4)      2592        activation_624[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_556 (Concatenate)   (None, 4, 4, 76)     0           concatenate_555[0][0]            \n",
            "                                                                 conv2d_627[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_627 (BatchN (None, 4, 4, 76)     304         concatenate_556[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_625 (Activation)     (None, 4, 4, 76)     0           batch_normalization_627[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_69 (AveragePo (None, 2, 2, 76)     0           activation_625[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_16 (Flatten)            (None, 304)          0           average_pooling2d_69[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense_16 (Dense)                (None, 10)           3050        flatten_16[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 123,786\n",
            "Trainable params: 117,250\n",
            "Non-trainable params: 6,536\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ytIG6BeCoOo0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# determine Loss function and Optimizer\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(lr=0.0001),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "crhGk7kEhXAz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3132
        },
        "outputId": "6f12783d-b2d3-45af-d936-4bcfedde4919"
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    517\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[128,48,32,32] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: training_9/RMSprop/gradients/zeros_269 = Fill[T=DT_FLOAT, _class=[\"loc:@concatenate_492/concat\"], index_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training_9/RMSprop/gradients/Shape_270, training_9/RMSprop/gradients/zeros_269/Const)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: loss_10/mul/_8061 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_26563_loss_10/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-127-1ed392c6bd73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                     validation_data=(x_test, y_test))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[128,48,32,32] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: training_9/RMSprop/gradients/zeros_269 = Fill[T=DT_FLOAT, _class=[\"loc:@concatenate_492/concat\"], index_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training_9/RMSprop/gradients/Shape_270, training_9/RMSprop/gradients/zeros_269/Const)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: loss_10/mul/_8061 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_26563_loss_10/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'training_9/RMSprop/gradients/zeros_269', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2828, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-127-1ed392c6bd73>\", line 5, in <module>\n    validation_data=(x_test, y_test))\n  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\", line 1682, in fit\n    self._make_train_function()\n  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\", line 992, in _make_train_function\n    loss=self.total_loss)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/optimizers.py\", line 244, in get_updates\n    grads = self.get_gradients(loss, params)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/optimizers.py\", line 78, in get_gradients\n    grads = K.gradients(loss, params)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 2519, in gradients\n    return tf.gradients(loss, variables, colocate_gradients_with_ops=True)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py\", line 488, in gradients\n    gate_gradients, aggregation_method, stop_gradients)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py\", line 616, in _GradientsHelper\n    out_grads[i] = control_flow_ops.ZerosLikeOutsideLoop(op, i)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 1470, in ZerosLikeOutsideLoop\n    return array_ops.zeros(zeros_shape, dtype=val.dtype)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\", line 1601, in zeros\n    output = fill(shape, constant(zero, dtype=dtype), name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 2583, in fill\n    \"Fill\", dims=dims, value=value, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3290, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1654, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[128,48,32,32] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: training_9/RMSprop/gradients/zeros_269 = Fill[T=DT_FLOAT, _class=[\"loc:@concatenate_492/concat\"], index_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training_9/RMSprop/gradients/Shape_270, training_9/RMSprop/gradients/zeros_269/Const)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: loss_10/mul/_8061 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_26563_loss_10/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "ZcWydmIVhZGr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "bb779d23-295b-468d-a914-bf1b0f73b45d"
      },
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 6s 565us/step\n",
            "Test loss: 1.52115950050354\n",
            "Test accuracy: 0.4376\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UE3lF6EH1r_L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "92c0f5ec-c9bb-4fdf-9a43-c67f3e598832"
      },
      "cell_type": "code",
      "source": [
        "# Save the trained weights in to .h5 format\n",
        "model.save_weights(\"DNST_model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ai-yZ2ED5AK1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('DNST_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Og56VCRh5j8V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "outputId": "f91e3f17-a3ff-4633-e9ad-9e0bc7caa817"
      },
      "cell_type": "code",
      "source": [
        "ls -lah\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 308K\r\n",
            "drwxr-xr-x 1 root root 4.0K May  6 15:33 \u001b[0m\u001b[01;34m.\u001b[0m/\r\n",
            "drwxr-xr-x 1 root root 4.0K May  6 11:15 \u001b[01;34m..\u001b[0m/\r\n",
            "drwx------ 4 root root 4.0K May  6 11:19 \u001b[01;34m.cache\u001b[0m/\r\n",
            "drwxr-xr-x 3 root root 4.0K May  6 11:19 \u001b[01;34m.config\u001b[0m/\r\n",
            "drwxr-xr-x 1 root root 4.0K Apr 30 16:29 \u001b[01;34mdatalab\u001b[0m/\r\n",
            "-rw-r--r-- 1 root root 264K May  6 18:11 DNST_model.h5\r\n",
            "drwxr-xr-x 4 root root 4.0K May  6 11:15 \u001b[01;34m.forever\u001b[0m/\r\n",
            "drwxr-xr-x 5 root root 4.0K May  6 11:19 \u001b[01;34m.ipython\u001b[0m/\r\n",
            "drwxr-xr-x 3 root root 4.0K May  6 11:20 \u001b[01;34m.keras\u001b[0m/\r\n",
            "drwx------ 3 root root 4.0K May  6 11:15 \u001b[01;34m.local\u001b[0m/\r\n",
            "drwx------ 3 root root 4.0K May  6 11:19 \u001b[01;34m.nv\u001b[0m/\r\n",
            "-rw------- 1 root root 1.0K May  6 11:15 .rnd\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qbAqWbaDFObj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}